# ğŸ§  Federated Learning com CompressÃ£o SemÃ¢ntica (GenIA)

> Um sistema de Aprendizado Federado resiliente a falhas de rede, utilizando Autoencoders para reconstruÃ§Ã£o semÃ¢ntica de dados perdidos.

![Status](https://img.shields.io/badge/Status-Active-success)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![Python](https://img.shields.io/badge/Python-3.9-yellow)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red)

## ğŸ“‹ Sobre o Projeto

Este projeto demonstra uma arquitetura de **Federated Learning (FL)** onde clientes treinam um modelo de IA localmente e enviam apenas os pesos para um servidor central.

A inovaÃ§Ã£o principal Ã© o mÃ³dulo **GenIA**, que permite que clientes em redes instÃ¡veis ("Client Noisy") enviem dados comprimidos ou incompletos. O servidor utiliza tÃ©cnicas de reconstruÃ§Ã£o semÃ¢ntica para preencher as lacunas antes da agregaÃ§Ã£o global.

### ğŸ—ï¸ Arquitetura

O sistema roda inteiramente em **Docker** e consiste em 5 containers:

1.  **ğŸ§  Server (Flask):** O "CÃ©rebro". Recebe pesos, reconstrÃ³i dados faltantes (Inpainting/GenIA) e agrega o modelo global (FedAvg).
2.  **ğŸ”µ Client Full:** Cliente com conexÃ£o perfeita. Treina e envia os pesos completos.
3.  **ğŸŸ  Client Noisy:** Cliente com conexÃ£o ruim (simulada). Aplica compressÃ£o semÃ¢ntica (envia apenas 50% dos dados) para economizar banda.
4.  **ğŸ“‰ Chaos Injector:** Container privilegiado que injeta falhas reais de rede (Packet Loss, Delay) na interface do *Client Noisy* usando `tc` (Traffic Control).
5.  **ğŸ›°ï¸ Dashboard (Streamlit):** Painel de controle para monitorar logs, mÃ©tricas em tempo real e interagir com a IA.

## ğŸš€ Como Rodar

### PrÃ©-requisitos
* Docker e Docker Compose instalados.

### Passo a Passo

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/SEU_USUARIO/federated-genia-demo.git](https://github.com/SEU_USUARIO/federated-genia-demo.git)
    cd federated-genia-demo
    ```

2.  **Inicie o ambiente:**
    ```bash
    docker-compose up --build
    ```

3.  **Acesse o Dashboard:**
    Abra seu navegador em: **[http://localhost:8501](http://localhost:8501)**

## ğŸ•¹ï¸ Como Usar (Workflow)

O sistema inicia em modo **PAUSED** para evitar treino com dataset vazio.

1.  **Ensinar (Teacher Forcing):**
    * No Dashboard, vÃ¡ na barra lateral "ğŸ“š Ensinar a IA".
    * Digite uma frase correta (Ex: `Federated`) e clique em **Salvar**.
    * *Adicione algumas variaÃ§Ãµes para melhorar o treino.*

2.  **Treinar:**
    * Clique no botÃ£o **â–¶ï¸ INICIAR** na barra lateral.
    * Acompanhe os terminais:
        * Os clientes vÃ£o baixar o Dataset, treinar localmente e enviar ao servidor.
        * O servidor vai agregar e salvar o `global_model.pth`.
    * Veja o grÃ¡fico de **Loss** caindo (o aprendizado acontecendo).

3.  **Testar (CorreÃ§Ã£o SemÃ¢ntica):**
    * Clique em **â¸ï¸ PAUSAR**.
    * VÃ¡ na Ã¡rea "ğŸ§ª Teste de CorreÃ§Ã£o".
    * Digite uma palavra com erro (Ex: `Federeted`).
    * Clique em **Verificar**.
    * A IA tentarÃ¡ reconstruir a palavra baseada no que aprendeu (Esperado: `Federated`).

## ğŸ› ï¸ Tecnologias Utilizadas

* **Linguagem:** Python 3.9
* **Machine Learning:** PyTorch (Autoencoder SemÃ¢ntico)
* **ComunicaÃ§Ã£o:** API REST (Flask)
* **Monitoramento:** Streamlit + SQLite
* **Infraestrutura:** Docker & Docker Compose
* **Rede:** `iproute2` (Traffic Control) para injeÃ§Ã£o de falhas.

## ğŸ“‚ Estrutura de Arquivos

```text
federated-genia-demo/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml        # ğŸ³ OrquestraÃ§Ã£o dos 5 containers
â”‚   â”œâ”€â”€ Dockerfile                # ğŸ³ Imagem base Python (ML + API + Dashboard)
â”‚   â””â”€â”€ requirements.txt          # ğŸ“¦ DependÃªncias (Torch, Flask, Streamlit)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                     # ğŸ§  NÃºcleo de ML e Federated Learning
â”‚   â”‚   â”œâ”€â”€ model_utils.py        # Arquitetura do Autoencoder SemÃ¢ntico (PyTorch)
â”‚   â”‚   â”œâ”€â”€ fedavg.py             # Algoritmo de agregaÃ§Ã£o Federada (FedAvg)
â”‚   â”‚   â”œâ”€â”€ compression.py        # CompressÃ£o semÃ¢ntica (drop / latent / mask)
â”‚   â”‚   â””â”€â”€ text_utils.py         # ConversÃ£o Texto â†” Tensor
â”‚   â”‚
â”‚   â”œâ”€â”€ server/                   # ğŸ§  Servidor Central (Agregador)
â”‚   â”‚   â”œâ”€â”€ server.py             # API Flask (upload, download, reconstruÃ§Ã£o)
â”‚   â”‚   â””â”€â”€ state.py              # Controle de ciclos, status e sincronizaÃ§Ã£o
â”‚   â”‚
â”‚   â”œâ”€â”€ client/                   # ğŸŸ ğŸ”µ Clientes Federados
â”‚   â”‚   â”œâ”€â”€ client.py             # LÃ³gica de treino local + envio de parÃ¢metros
â”‚   â”‚   â””â”€â”€ node_config.py        # ConfiguraÃ§Ã£o (Full / Noisy / CompressÃ£o)
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/                # ğŸ›°ï¸ Painel de Observabilidade
â”‚   â”‚   â”œâ”€â”€ dashboard.py          # Interface Streamlit
â”‚   â”‚   â””â”€â”€ charts.py             # GrÃ¡ficos (loss, banda, latÃªncia)
â”‚   â”‚
â”‚   â”œâ”€â”€ chaos/                    # ğŸ“‰ InjeÃ§Ã£o de falhas de rede
â”‚   â”‚   â””â”€â”€ chaos_injector.sh     # Script tc (delay, loss, bandwidth)
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                  # ğŸ’¾ Artefatos gerados (runtime)
â”‚   â”‚   â”œâ”€â”€ dataset.txt           # Frases ensinadas pelo usuÃ¡rio
â”‚   â”‚   â”œâ”€â”€ global_model.pth      # Modelo global agregado
â”‚   â”‚   â”œâ”€â”€ metrics.db            # Banco SQLite de mÃ©tricas
â”‚   â”‚   â””â”€â”€ status.json           # Estado do sistema (RUNNING / PAUSED)
â”‚   â”‚
â”‚   â””â”€â”€ logs/                     # ğŸ“œ Logs de execuÃ§Ã£o (gerado)
â”‚
â”œâ”€â”€ .gitignore                    # Arquivos ignorados pelo Git
â”œâ”€â”€ README.md                     # ğŸ“˜ DocumentaÃ§Ã£o do projeto
â””â”€â”€ LICENSE                       # (Opcional) LicenÃ§a do projeto
```

## âš ï¸ Troubleshooting

Se precisar reiniciar do zero (limpar banco de dados e modelos salvos):

```bash
docker-compose down
# No Linux/Mac:
rm src/metrics.db src/global_model.pth src/dataset.txt src/status.json
# No Windows (PowerShell):
rm src/metrics.db, src/global_model.pth, src/dataset.txt, src/status.json
docker-compose up --build